2025-01-08 16:27:49 - INFO - ------------------------------------------------------------------------------------------------
2025-01-08 16:27:49 - INFO - starting new training !!!!
2025-01-08 16:27:49 - INFO - ------------------------------------------------------------------------------------------------
2025-01-08 16:27:49 - INFO - Namespace(lr=0.0001, batch=32, epoch=50, data_dir='/home/akshit/Desktop/workspace/python/MNIST/data', save_dir='model_parameter_VAE', kl_weight=0.0, save_freq=2, log_dir='logs', gamma=0.1, step_size=2, model_path='')
2025-01-08 16:27:49 - INFO - parameters are being saved at :model_parameter_VAE/18
2025-01-08 16:27:49 - INFO - VAE_conv(
  (encoder): Sequential(
    (0): Sequential(
      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): LeakyReLU(negative_slope=0.01)
      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (1): Sequential(
      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): LeakyReLU(negative_slope=0.01)
      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (2): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): LeakyReLU(negative_slope=0.01)
    )
    (3): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): LeakyReLU(negative_slope=0.01)
    )
  )
  (mu): Linear(in_features=3136, out_features=128, bias=True)
  (log_var): Linear(in_features=3136, out_features=128, bias=True)
  (project_back): Linear(in_features=128, out_features=3136, bias=True)
  (decoder): Sequential(
    (0): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): LeakyReLU(negative_slope=0.01)
    )
    (1): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): LeakyReLU(negative_slope=0.01)
    )
    (2): Sequential(
      (0): Sequential(
        (0): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
        (1): LeakyReLU(negative_slope=0.01)
      )
    )
    (3): Sequential(
      (0): ConvTranspose2d(32, 1, kernel_size=(2, 2), stride=(2, 2))
      (1): Sigmoid()
    )
  )
)
2025-01-08 16:27:49 - INFO - epoch:0/50 iteration:0/1876 batch loss is :7741.1772
2025-01-08 16:27:53 - INFO - epoch:0/50 iteration:50/1876 batch loss is :6757.1484
2025-01-08 16:27:55 - INFO - epoch:0/50 iteration:100/1876 batch loss is :7463.5957
2025-01-08 16:27:56 - INFO - epoch:0/50 iteration:150/1876 batch loss is :7176.3442
2025-01-08 16:27:58 - INFO - epoch:0/50 iteration:200/1876 batch loss is :8323.5752
2025-01-08 16:28:00 - INFO - epoch:0/50 iteration:250/1876 batch loss is :6172.6831
2025-01-08 16:28:01 - INFO - epoch:0/50 iteration:300/1876 batch loss is :7663.4048
2025-01-08 16:28:02 - INFO - epoch:0/50 iteration:350/1876 batch loss is :7840.4478
2025-01-08 16:28:03 - INFO - epoch:0/50 iteration:400/1876 batch loss is :7269.4062
2025-01-08 16:28:04 - INFO - epoch:0/50 iteration:450/1876 batch loss is :7882.7397
2025-01-08 16:28:05 - INFO - epoch:0/50 iteration:500/1876 batch loss is :7291.2817
2025-01-08 16:28:07 - INFO - epoch:0/50 iteration:550/1876 batch loss is :6466.4502
2025-01-08 16:28:08 - INFO - epoch:0/50 iteration:600/1876 batch loss is :6570.7026
2025-01-08 16:28:09 - INFO - epoch:0/50 iteration:650/1876 batch loss is :6614.3901
2025-01-08 16:28:10 - INFO - epoch:0/50 iteration:700/1876 batch loss is :6418.1938
2025-01-08 16:28:12 - INFO - epoch:0/50 iteration:750/1876 batch loss is :6955.6479
2025-01-08 16:28:13 - INFO - epoch:0/50 iteration:800/1876 batch loss is :6992.3623
2025-01-08 16:28:14 - INFO - epoch:0/50 iteration:850/1876 batch loss is :7028.9038
2025-01-08 16:28:16 - INFO - epoch:0/50 iteration:900/1876 batch loss is :6861.6631
2025-01-08 16:28:17 - INFO - epoch:0/50 iteration:950/1876 batch loss is :7340.1855
2025-01-08 16:28:18 - INFO - epoch:0/50 iteration:1000/1876 batch loss is :6916.4609
2025-01-08 16:28:19 - INFO - epoch:0/50 iteration:1050/1876 batch loss is :7000.8003
2025-01-08 16:28:21 - INFO - epoch:0/50 iteration:1100/1876 batch loss is :7288.1890
2025-01-08 16:28:22 - INFO - epoch:0/50 iteration:1150/1876 batch loss is :7252.6367
2025-01-08 16:28:24 - INFO - epoch:0/50 iteration:1200/1876 batch loss is :6739.7764
2025-01-08 16:28:25 - INFO - epoch:0/50 iteration:1250/1876 batch loss is :6861.8608
2025-01-08 16:28:26 - INFO - epoch:0/50 iteration:1300/1876 batch loss is :7485.7319
2025-01-08 16:28:27 - INFO - epoch:0/50 iteration:1350/1876 batch loss is :7301.8711
2025-01-08 16:28:29 - INFO - epoch:0/50 iteration:1400/1876 batch loss is :6952.4482
2025-01-08 16:28:30 - INFO - epoch:0/50 iteration:1450/1876 batch loss is :6907.2466
2025-01-08 16:28:31 - INFO - epoch:0/50 iteration:1500/1876 batch loss is :7845.4673
2025-01-08 16:28:32 - INFO - epoch:0/50 iteration:1550/1876 batch loss is :7238.6748
2025-01-08 16:28:34 - INFO - epoch:0/50 iteration:1600/1876 batch loss is :7211.3643
2025-01-08 16:28:35 - INFO - epoch:0/50 iteration:1650/1876 batch loss is :7051.7798
2025-01-08 16:28:37 - INFO - epoch:0/50 iteration:1700/1876 batch loss is :6874.8794
2025-01-08 16:28:38 - INFO - epoch:0/50 iteration:1750/1876 batch loss is :7470.4829
2025-01-08 16:28:39 - INFO - epoch:0/50 iteration:1800/1876 batch loss is :7382.0015
2025-01-08 16:28:40 - INFO - epoch:0/50 iteration:1850/1876 batch loss is :7253.6250
2025-01-08 16:28:42 - INFO - Epoch:0/50 Loss is :7218.8647
2025-01-08 16:28:42 - INFO - average reconstruction loss is :7218.8647
2025-01-08 16:28:42 - INFO - average kl divergence is : 0.0000
2025-01-08 16:28:45 - INFO - VAL loss :7351.6768
2025-01-08 16:28:45 - INFO - epoch:1/50 iteration:0/1876 batch loss is :7595.7192
2025-01-08 16:28:46 - INFO - epoch:1/50 iteration:50/1876 batch loss is :7479.1484
2025-01-08 16:28:47 - INFO - epoch:1/50 iteration:100/1876 batch loss is :6533.6006
2025-01-08 16:28:48 - INFO - epoch:1/50 iteration:150/1876 batch loss is :6824.2251
2025-01-08 16:28:49 - INFO - epoch:1/50 iteration:200/1876 batch loss is :6636.0273
2025-01-08 16:28:50 - INFO - epoch:1/50 iteration:250/1876 batch loss is :6773.1226
2025-01-08 16:28:51 - INFO - epoch:1/50 iteration:300/1876 batch loss is :7875.2212
2025-01-08 16:28:52 - INFO - epoch:1/50 iteration:350/1876 batch loss is :7187.7021
2025-01-08 16:28:54 - INFO - epoch:1/50 iteration:400/1876 batch loss is :7456.2080
2025-01-08 16:28:55 - INFO - epoch:1/50 iteration:450/1876 batch loss is :6831.9409
2025-01-08 16:28:56 - INFO - epoch:1/50 iteration:500/1876 batch loss is :7820.6938
2025-01-08 16:28:58 - INFO - epoch:1/50 iteration:550/1876 batch loss is :6556.7607
2025-01-08 16:28:59 - INFO - epoch:1/50 iteration:600/1876 batch loss is :6759.8145
2025-01-08 16:29:00 - INFO - epoch:1/50 iteration:650/1876 batch loss is :7293.2578
2025-01-08 16:29:01 - INFO - epoch:1/50 iteration:700/1876 batch loss is :7314.7144
2025-01-08 16:29:02 - INFO - epoch:1/50 iteration:750/1876 batch loss is :7409.0381
2025-01-08 16:29:03 - INFO - epoch:1/50 iteration:800/1876 batch loss is :7406.8750
2025-01-08 16:29:04 - INFO - epoch:1/50 iteration:850/1876 batch loss is :7342.7568
2025-01-08 16:29:05 - INFO - epoch:1/50 iteration:900/1876 batch loss is :7204.2271
2025-01-08 16:29:06 - INFO - epoch:1/50 iteration:950/1876 batch loss is :7592.6938
2025-01-08 16:29:07 - INFO - epoch:1/50 iteration:1000/1876 batch loss is :6407.0693
2025-01-08 16:29:08 - INFO - epoch:1/50 iteration:1050/1876 batch loss is :7431.3706
2025-01-08 16:29:09 - INFO - epoch:1/50 iteration:1100/1876 batch loss is :7003.8701
2025-01-08 16:29:10 - INFO - epoch:1/50 iteration:1150/1876 batch loss is :7756.3140
2025-01-08 16:29:11 - INFO - epoch:1/50 iteration:1200/1876 batch loss is :6810.6294
2025-01-08 16:29:12 - INFO - epoch:1/50 iteration:1250/1876 batch loss is :6868.0005
2025-01-08 16:29:13 - INFO - epoch:1/50 iteration:1300/1876 batch loss is :7261.3896
2025-01-08 16:29:14 - INFO - epoch:1/50 iteration:1350/1876 batch loss is :7237.6963
2025-01-08 16:29:15 - INFO - epoch:1/50 iteration:1400/1876 batch loss is :7814.9985
2025-01-08 16:29:16 - INFO - epoch:1/50 iteration:1450/1876 batch loss is :7866.3838
2025-01-08 16:29:17 - INFO - epoch:1/50 iteration:1500/1876 batch loss is :7702.1440
2025-01-08 16:29:18 - INFO - epoch:1/50 iteration:1550/1876 batch loss is :7713.2935
2025-01-08 16:29:19 - INFO - epoch:1/50 iteration:1600/1876 batch loss is :7258.5874
2025-01-08 16:29:21 - INFO - epoch:1/50 iteration:1650/1876 batch loss is :7860.8877
2025-01-08 16:29:23 - INFO - epoch:1/50 iteration:1700/1876 batch loss is :6683.0444
2025-01-08 16:29:24 - INFO - epoch:1/50 iteration:1750/1876 batch loss is :7211.0430
2025-01-08 16:29:25 - INFO - epoch:1/50 iteration:1800/1876 batch loss is :6978.0034
2025-01-08 16:29:26 - INFO - epoch:1/50 iteration:1850/1876 batch loss is :7110.2617
2025-01-08 16:29:26 - INFO - Epoch:1/50 Loss is :7218.3140
2025-01-08 16:29:26 - INFO - average reconstruction loss is :7218.3140
2025-01-08 16:29:26 - INFO - average kl divergence is : 0.0000
2025-01-08 16:29:26 - INFO - epoch:2/50 iteration:0/1876 batch loss is :6346.3335
2025-01-08 16:29:27 - INFO - epoch:2/50 iteration:50/1876 batch loss is :6789.5415
2025-01-08 16:29:28 - INFO - epoch:2/50 iteration:100/1876 batch loss is :6615.8247
2025-01-08 16:29:29 - INFO - epoch:2/50 iteration:150/1876 batch loss is :7192.4004
2025-01-08 16:29:30 - INFO - epoch:2/50 iteration:200/1876 batch loss is :7807.5957
2025-01-08 16:29:31 - INFO - epoch:2/50 iteration:250/1876 batch loss is :7360.7334
2025-01-08 16:29:32 - INFO - epoch:2/50 iteration:300/1876 batch loss is :6682.4414
2025-01-08 16:29:33 - INFO - epoch:2/50 iteration:350/1876 batch loss is :7692.3975
2025-01-08 16:29:34 - INFO - epoch:2/50 iteration:400/1876 batch loss is :7304.3105
2025-01-08 16:29:35 - INFO - epoch:2/50 iteration:450/1876 batch loss is :6914.6812
2025-01-08 16:29:36 - INFO - epoch:2/50 iteration:500/1876 batch loss is :7335.3604
2025-01-08 16:29:38 - INFO - epoch:2/50 iteration:550/1876 batch loss is :7174.6924
2025-01-08 16:29:39 - INFO - epoch:2/50 iteration:600/1876 batch loss is :7475.2061
2025-01-08 16:29:40 - INFO - epoch:2/50 iteration:650/1876 batch loss is :6753.0942
2025-01-08 16:29:41 - INFO - epoch:2/50 iteration:700/1876 batch loss is :6549.5039
2025-01-08 16:29:43 - INFO - epoch:2/50 iteration:750/1876 batch loss is :8185.6440
2025-01-08 16:29:44 - INFO - epoch:2/50 iteration:800/1876 batch loss is :7437.1631
2025-01-08 16:29:46 - INFO - epoch:2/50 iteration:850/1876 batch loss is :8229.7676
2025-01-08 16:29:48 - INFO - epoch:2/50 iteration:900/1876 batch loss is :6948.1641
2025-01-08 16:29:48 - INFO - epoch:2/50 iteration:950/1876 batch loss is :7215.5444
2025-01-08 16:29:50 - INFO - epoch:2/50 iteration:1000/1876 batch loss is :7782.5903
2025-01-08 16:29:51 - INFO - epoch:2/50 iteration:1050/1876 batch loss is :6999.1938
2025-01-08 16:29:52 - INFO - epoch:2/50 iteration:1100/1876 batch loss is :7317.4399
2025-01-08 16:29:53 - INFO - epoch:2/50 iteration:1150/1876 batch loss is :7204.3423
2025-01-08 16:29:54 - INFO - epoch:2/50 iteration:1200/1876 batch loss is :7420.0586
2025-01-08 16:29:55 - INFO - epoch:2/50 iteration:1250/1876 batch loss is :7715.3652
2025-01-08 16:29:56 - INFO - epoch:2/50 iteration:1300/1876 batch loss is :6971.0396
2025-01-08 16:29:57 - INFO - epoch:2/50 iteration:1350/1876 batch loss is :8232.9912
2025-01-08 16:29:58 - INFO - epoch:2/50 iteration:1400/1876 batch loss is :7414.1851
2025-01-08 16:30:00 - INFO - epoch:2/50 iteration:1450/1876 batch loss is :6505.9585
2025-01-08 16:30:00 - INFO - epoch:2/50 iteration:1500/1876 batch loss is :7492.1299
2025-01-08 16:30:01 - INFO - epoch:2/50 iteration:1550/1876 batch loss is :6553.0723
2025-01-08 16:30:02 - INFO - epoch:2/50 iteration:1600/1876 batch loss is :6851.6201
2025-01-08 16:30:03 - INFO - epoch:2/50 iteration:1650/1876 batch loss is :7072.2495
2025-01-08 16:30:04 - INFO - epoch:2/50 iteration:1700/1876 batch loss is :7651.6938
2025-01-08 16:30:05 - INFO - epoch:2/50 iteration:1750/1876 batch loss is :7407.8608
2025-01-08 16:30:06 - INFO - epoch:2/50 iteration:1800/1876 batch loss is :6872.7119
2025-01-08 16:30:08 - INFO - epoch:2/50 iteration:1850/1876 batch loss is :7478.3701
2025-01-08 16:30:09 - INFO - Epoch:2/50 Loss is :7218.3105
2025-01-08 16:30:09 - INFO - average reconstruction loss is :7218.3105
2025-01-08 16:30:09 - INFO - average kl divergence is : 0.0000
2025-01-08 16:30:11 - INFO - VAL loss :7351.6655
2025-01-08 16:30:11 - INFO - epoch:3/50 iteration:0/1876 batch loss is :6773.0830
2025-01-08 16:30:13 - INFO - epoch:3/50 iteration:50/1876 batch loss is :7256.5620
2025-01-08 16:30:15 - INFO - epoch:3/50 iteration:100/1876 batch loss is :7226.0728
2025-01-08 16:30:17 - INFO - epoch:3/50 iteration:150/1876 batch loss is :7922.5186
2025-01-08 16:30:18 - INFO - epoch:3/50 iteration:200/1876 batch loss is :7186.8940
2025-01-08 16:30:20 - INFO - epoch:3/50 iteration:250/1876 batch loss is :7363.2441
2025-01-08 16:30:22 - INFO - epoch:3/50 iteration:300/1876 batch loss is :6822.8062
2025-01-08 16:30:24 - INFO - epoch:3/50 iteration:350/1876 batch loss is :7133.5273
2025-01-08 16:30:27 - INFO - epoch:3/50 iteration:400/1876 batch loss is :7833.2954
2025-01-08 16:30:29 - INFO - epoch:3/50 iteration:450/1876 batch loss is :6245.7144
2025-01-08 16:30:31 - INFO - epoch:3/50 iteration:500/1876 batch loss is :6665.5493
2025-01-08 16:30:32 - INFO - epoch:3/50 iteration:550/1876 batch loss is :7263.7310
2025-01-08 16:30:34 - INFO - epoch:3/50 iteration:600/1876 batch loss is :7189.0034
2025-01-08 16:30:36 - INFO - epoch:3/50 iteration:650/1876 batch loss is :6575.0933
2025-01-08 16:30:38 - INFO - epoch:3/50 iteration:700/1876 batch loss is :7461.6797
2025-01-08 16:30:40 - INFO - epoch:3/50 iteration:750/1876 batch loss is :6499.1191
2025-01-08 16:30:41 - INFO - epoch:3/50 iteration:800/1876 batch loss is :7178.1646
2025-01-08 16:30:43 - INFO - epoch:3/50 iteration:850/1876 batch loss is :8384.8105
2025-01-08 16:30:45 - INFO - epoch:3/50 iteration:900/1876 batch loss is :8069.1558
2025-01-08 16:30:46 - INFO - epoch:3/50 iteration:950/1876 batch loss is :6692.6523
2025-01-08 16:30:47 - INFO - epoch:3/50 iteration:1000/1876 batch loss is :7747.6416
2025-01-08 16:30:48 - INFO - epoch:3/50 iteration:1050/1876 batch loss is :8539.5137
2025-01-08 16:30:50 - INFO - epoch:3/50 iteration:1100/1876 batch loss is :6028.3037
2025-01-08 16:30:51 - INFO - epoch:3/50 iteration:1150/1876 batch loss is :7091.5664
2025-01-08 16:30:52 - INFO - epoch:3/50 iteration:1200/1876 batch loss is :7882.2500
2025-01-08 16:30:53 - INFO - epoch:3/50 iteration:1250/1876 batch loss is :6989.3164
2025-01-08 16:30:56 - INFO - epoch:3/50 iteration:1300/1876 batch loss is :7106.9258
2025-01-08 16:30:58 - INFO - epoch:3/50 iteration:1350/1876 batch loss is :7593.2119
2025-01-08 16:30:59 - INFO - epoch:3/50 iteration:1400/1876 batch loss is :6638.1108
2025-01-08 16:31:00 - INFO - epoch:3/50 iteration:1450/1876 batch loss is :7209.3623
2025-01-08 16:31:01 - INFO - epoch:3/50 iteration:1500/1876 batch loss is :6707.2651
2025-01-08 16:31:02 - INFO - epoch:3/50 iteration:1550/1876 batch loss is :6482.8403
2025-01-08 16:31:03 - INFO - epoch:3/50 iteration:1600/1876 batch loss is :7635.1162
2025-01-08 16:31:04 - INFO - epoch:3/50 iteration:1650/1876 batch loss is :6487.2163
2025-01-08 16:31:05 - INFO - epoch:3/50 iteration:1700/1876 batch loss is :7656.9390
