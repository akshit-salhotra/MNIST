2025-01-09 14:07:53 - INFO - ------------------------------------------------------------------------------------------------
2025-01-09 14:07:53 - INFO - starting new training !!!!
2025-01-09 14:07:53 - INFO - ------------------------------------------------------------------------------------------------
2025-01-09 14:07:53 - INFO - Namespace(lr=0.0001, batch=32, epoch=50, data_dir='/home/akshit/Desktop/workspace/python/MNIST/data', save_dir='model_parameter_VAE', kl_weight=0.0, save_freq=2, log_dir='logs', gamma=0.1, step_size=2, model_path=None)
2025-01-09 14:07:53 - INFO - parameters are being saved at :model_parameter_VAE/23
2025-01-09 14:07:53 - INFO - VAE_conv(
  (encoder): Sequential(
    (0): Sequential(
      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): LeakyReLU(negative_slope=0.01)
      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (1): Sequential(
      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): LeakyReLU(negative_slope=0.01)
      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (2): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): LeakyReLU(negative_slope=0.01)
    )
    (3): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): LeakyReLU(negative_slope=0.01)
    )
  )
  (mu): Linear(in_features=3136, out_features=128, bias=True)
  (log_var): Linear(in_features=3136, out_features=128, bias=True)
  (project_back): Linear(in_features=128, out_features=3136, bias=True)
  (decoder): Sequential(
    (0): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): LeakyReLU(negative_slope=0.01)
    )
    (1): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): LeakyReLU(negative_slope=0.01)
    )
    (2): Sequential(
      (0): Sequential(
        (0): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
        (1): LeakyReLU(negative_slope=0.01)
      )
    )
    (3): Sequential(
      (0): ConvTranspose2d(32, 1, kernel_size=(2, 2), stride=(2, 2))
      (1): Sigmoid()
    )
  )
)
2025-01-09 14:07:53 - INFO - epoch:0/50 iteration:0/1876 batch loss is :7067.8940
2025-01-09 14:07:54 - INFO - epoch:0/50 iteration:50/1876 batch loss is :7872.0088
2025-01-09 14:07:56 - INFO - epoch:0/50 iteration:100/1876 batch loss is :6252.4067
2025-01-09 14:07:57 - INFO - epoch:0/50 iteration:150/1876 batch loss is :7827.9248
2025-01-09 14:07:58 - INFO - epoch:0/50 iteration:200/1876 batch loss is :7923.4297
2025-01-09 14:07:59 - INFO - epoch:0/50 iteration:250/1876 batch loss is :7454.7651
2025-01-09 14:08:00 - INFO - epoch:0/50 iteration:300/1876 batch loss is :7387.8813
2025-01-09 14:08:02 - INFO - epoch:0/50 iteration:350/1876 batch loss is :6679.2754
2025-01-09 14:08:03 - INFO - epoch:0/50 iteration:400/1876 batch loss is :7510.6646
2025-01-09 14:08:04 - INFO - epoch:0/50 iteration:450/1876 batch loss is :7773.9224
2025-01-09 14:08:05 - INFO - epoch:0/50 iteration:500/1876 batch loss is :6981.2061
2025-01-09 14:08:06 - INFO - epoch:0/50 iteration:550/1876 batch loss is :7417.3335
2025-01-09 14:08:08 - INFO - epoch:0/50 iteration:600/1876 batch loss is :7564.1899
2025-01-09 14:08:09 - INFO - epoch:0/50 iteration:650/1876 batch loss is :6925.3159
2025-01-09 14:08:10 - INFO - epoch:0/50 iteration:700/1876 batch loss is :7013.2847
2025-01-09 14:08:11 - INFO - epoch:0/50 iteration:750/1876 batch loss is :7150.7959
2025-01-09 14:08:12 - INFO - epoch:0/50 iteration:800/1876 batch loss is :6910.1475
2025-01-09 14:08:14 - INFO - epoch:0/50 iteration:850/1876 batch loss is :7361.3569
2025-01-09 14:08:15 - INFO - epoch:0/50 iteration:900/1876 batch loss is :7486.9956
2025-01-09 14:08:16 - INFO - epoch:0/50 iteration:950/1876 batch loss is :7962.9268
2025-01-09 14:08:17 - INFO - epoch:0/50 iteration:1000/1876 batch loss is :7268.7749
2025-01-09 14:08:18 - INFO - epoch:0/50 iteration:1050/1876 batch loss is :7127.7544
2025-01-09 14:08:20 - INFO - epoch:0/50 iteration:1100/1876 batch loss is :7361.3149
2025-01-09 14:08:21 - INFO - epoch:0/50 iteration:1150/1876 batch loss is :7424.1899
2025-01-09 14:08:22 - INFO - epoch:0/50 iteration:1200/1876 batch loss is :6939.0986
2025-01-09 14:08:24 - INFO - epoch:0/50 iteration:1250/1876 batch loss is :6769.3418
2025-01-09 14:08:25 - INFO - epoch:0/50 iteration:1300/1876 batch loss is :8017.7295
2025-01-09 14:08:26 - INFO - epoch:0/50 iteration:1350/1876 batch loss is :7061.4834
2025-01-09 14:08:27 - INFO - epoch:0/50 iteration:1400/1876 batch loss is :7727.5767
2025-01-09 14:08:29 - INFO - epoch:0/50 iteration:1450/1876 batch loss is :8156.9424
2025-01-09 14:08:30 - INFO - epoch:0/50 iteration:1500/1876 batch loss is :6938.9077
2025-01-09 14:08:31 - INFO - epoch:0/50 iteration:1550/1876 batch loss is :6455.7144
2025-01-09 14:08:33 - INFO - epoch:0/50 iteration:1600/1876 batch loss is :7484.2358
2025-01-09 14:08:34 - INFO - epoch:0/50 iteration:1650/1876 batch loss is :7885.3027
2025-01-09 14:08:36 - INFO - epoch:0/50 iteration:1700/1876 batch loss is :6910.8037
2025-01-09 14:08:37 - INFO - epoch:0/50 iteration:1750/1876 batch loss is :6995.9077
2025-01-09 14:08:38 - INFO - epoch:0/50 iteration:1800/1876 batch loss is :7799.4214
2025-01-09 14:08:39 - INFO - epoch:0/50 iteration:1850/1876 batch loss is :6806.6001
2025-01-09 14:08:40 - INFO - Epoch:0/50 Loss is :7213.5752
2025-01-09 14:08:40 - INFO - average reconstruction loss is :7213.5752
2025-01-09 14:08:40 - INFO - average kl divergence is : 0.0000
2025-01-09 14:08:44 - INFO - VAL loss :7346.5161
2025-01-09 14:08:44 - INFO - epoch:1/50 iteration:0/1876 batch loss is :8213.2910
2025-01-09 14:08:45 - INFO - epoch:1/50 iteration:50/1876 batch loss is :7880.4580
2025-01-09 14:08:47 - INFO - epoch:1/50 iteration:100/1876 batch loss is :6648.7725
2025-01-09 14:08:48 - INFO - epoch:1/50 iteration:150/1876 batch loss is :7191.2651
2025-01-09 14:08:49 - INFO - epoch:1/50 iteration:200/1876 batch loss is :6552.4287
2025-01-09 14:08:51 - INFO - epoch:1/50 iteration:250/1876 batch loss is :6970.7837
2025-01-09 14:08:52 - INFO - epoch:1/50 iteration:300/1876 batch loss is :7245.9546
2025-01-09 14:08:53 - INFO - epoch:1/50 iteration:350/1876 batch loss is :6836.5459
2025-01-09 14:08:54 - INFO - epoch:1/50 iteration:400/1876 batch loss is :7189.8110
2025-01-09 14:08:56 - INFO - epoch:1/50 iteration:450/1876 batch loss is :7393.8472
2025-01-09 14:08:57 - INFO - epoch:1/50 iteration:500/1876 batch loss is :6764.8882
2025-01-09 14:08:58 - INFO - epoch:1/50 iteration:550/1876 batch loss is :7417.4917
2025-01-09 14:09:00 - INFO - epoch:1/50 iteration:600/1876 batch loss is :7198.3765
2025-01-09 14:09:01 - INFO - epoch:1/50 iteration:650/1876 batch loss is :7125.6914
2025-01-09 14:09:02 - INFO - epoch:1/50 iteration:700/1876 batch loss is :6765.7305
2025-01-09 14:09:04 - INFO - epoch:1/50 iteration:750/1876 batch loss is :7729.4233
2025-01-09 14:09:05 - INFO - epoch:1/50 iteration:800/1876 batch loss is :7176.6562
2025-01-09 14:09:06 - INFO - epoch:1/50 iteration:850/1876 batch loss is :6668.8481
2025-01-09 14:09:08 - INFO - epoch:1/50 iteration:900/1876 batch loss is :7475.4834
2025-01-09 14:09:09 - INFO - epoch:1/50 iteration:950/1876 batch loss is :6909.9058
2025-01-09 14:09:10 - INFO - epoch:1/50 iteration:1000/1876 batch loss is :7127.5088
2025-01-09 14:09:11 - INFO - epoch:1/50 iteration:1050/1876 batch loss is :7122.1953
2025-01-09 14:09:13 - INFO - epoch:1/50 iteration:1100/1876 batch loss is :7317.0186
2025-01-09 14:09:14 - INFO - epoch:1/50 iteration:1150/1876 batch loss is :7030.0625
2025-01-09 14:09:15 - INFO - epoch:1/50 iteration:1200/1876 batch loss is :7666.2524
2025-01-09 14:09:16 - INFO - epoch:1/50 iteration:1250/1876 batch loss is :7228.5688
2025-01-09 14:09:18 - INFO - epoch:1/50 iteration:1300/1876 batch loss is :8100.0049
2025-01-09 14:09:19 - INFO - epoch:1/50 iteration:1350/1876 batch loss is :6704.9258
2025-01-09 14:09:20 - INFO - epoch:1/50 iteration:1400/1876 batch loss is :7521.8242
2025-01-09 14:09:22 - INFO - epoch:1/50 iteration:1450/1876 batch loss is :6797.4082
2025-01-09 14:09:23 - INFO - epoch:1/50 iteration:1500/1876 batch loss is :7544.2578
2025-01-09 14:09:24 - INFO - epoch:1/50 iteration:1550/1876 batch loss is :7429.5132
2025-01-09 14:09:26 - INFO - epoch:1/50 iteration:1600/1876 batch loss is :7321.3271
2025-01-09 14:09:27 - INFO - epoch:1/50 iteration:1650/1876 batch loss is :7179.2646
2025-01-09 14:09:28 - INFO - epoch:1/50 iteration:1700/1876 batch loss is :7974.0972
2025-01-09 14:09:30 - INFO - epoch:1/50 iteration:1750/1876 batch loss is :7460.8750
2025-01-09 14:09:31 - INFO - epoch:1/50 iteration:1800/1876 batch loss is :7764.2017
2025-01-09 14:09:32 - INFO - epoch:1/50 iteration:1850/1876 batch loss is :7861.1597
2025-01-09 14:09:33 - INFO - Epoch:1/50 Loss is :7213.0078
2025-01-09 14:09:33 - INFO - average reconstruction loss is :7213.0078
2025-01-09 14:09:33 - INFO - average kl divergence is : 0.0000
2025-01-09 14:09:33 - INFO - epoch:2/50 iteration:0/1876 batch loss is :8203.9248
2025-01-09 14:09:35 - INFO - epoch:2/50 iteration:50/1876 batch loss is :6935.3379
2025-01-09 14:09:36 - INFO - epoch:2/50 iteration:100/1876 batch loss is :7175.6914
2025-01-09 14:09:37 - INFO - epoch:2/50 iteration:150/1876 batch loss is :7422.6289
2025-01-09 14:09:39 - INFO - epoch:2/50 iteration:200/1876 batch loss is :7065.1167
2025-01-09 14:09:40 - INFO - epoch:2/50 iteration:250/1876 batch loss is :7054.0576
2025-01-09 14:09:42 - INFO - epoch:2/50 iteration:300/1876 batch loss is :6988.3018
2025-01-09 14:09:43 - INFO - epoch:2/50 iteration:350/1876 batch loss is :6658.1914
2025-01-09 14:09:44 - INFO - epoch:2/50 iteration:400/1876 batch loss is :7147.7852
2025-01-09 14:09:46 - INFO - epoch:2/50 iteration:450/1876 batch loss is :7040.0693
2025-01-09 14:09:47 - INFO - epoch:2/50 iteration:500/1876 batch loss is :7120.5894
2025-01-09 14:09:48 - INFO - epoch:2/50 iteration:550/1876 batch loss is :7267.0298
2025-01-09 14:09:50 - INFO - epoch:2/50 iteration:600/1876 batch loss is :6920.6875
2025-01-09 14:09:51 - INFO - epoch:2/50 iteration:650/1876 batch loss is :7384.1357
2025-01-09 14:09:53 - INFO - epoch:2/50 iteration:700/1876 batch loss is :6930.9106
2025-01-09 14:09:54 - INFO - epoch:2/50 iteration:750/1876 batch loss is :6933.1914
2025-01-09 14:09:55 - INFO - epoch:2/50 iteration:800/1876 batch loss is :6261.8994
2025-01-09 14:09:57 - INFO - epoch:2/50 iteration:850/1876 batch loss is :6884.7441
2025-01-09 14:09:58 - INFO - epoch:2/50 iteration:900/1876 batch loss is :7054.3462
2025-01-09 14:10:00 - INFO - epoch:2/50 iteration:950/1876 batch loss is :7701.1562
2025-01-09 14:10:01 - INFO - epoch:2/50 iteration:1000/1876 batch loss is :6999.0811
2025-01-09 14:10:02 - INFO - epoch:2/50 iteration:1050/1876 batch loss is :7445.2085
2025-01-09 14:10:04 - INFO - epoch:2/50 iteration:1100/1876 batch loss is :7083.6899
2025-01-09 14:10:05 - INFO - epoch:2/50 iteration:1150/1876 batch loss is :6741.0742
2025-01-09 14:10:07 - INFO - epoch:2/50 iteration:1200/1876 batch loss is :6982.3726
2025-01-09 14:10:08 - INFO - epoch:2/50 iteration:1250/1876 batch loss is :7569.4629
2025-01-09 14:10:09 - INFO - epoch:2/50 iteration:1300/1876 batch loss is :7493.6768
2025-01-09 14:10:11 - INFO - epoch:2/50 iteration:1350/1876 batch loss is :7997.6147
2025-01-09 14:10:12 - INFO - epoch:2/50 iteration:1400/1876 batch loss is :8003.7769
2025-01-09 14:10:14 - INFO - epoch:2/50 iteration:1450/1876 batch loss is :8782.3574
2025-01-09 14:10:15 - INFO - epoch:2/50 iteration:1500/1876 batch loss is :6538.4390
2025-01-09 14:10:17 - INFO - epoch:2/50 iteration:1550/1876 batch loss is :6970.0649
2025-01-09 14:10:18 - INFO - epoch:2/50 iteration:1600/1876 batch loss is :7713.7729
2025-01-09 14:10:20 - INFO - epoch:2/50 iteration:1650/1876 batch loss is :7341.8481
2025-01-09 14:10:22 - INFO - epoch:2/50 iteration:1700/1876 batch loss is :7649.8413
2025-01-09 14:10:24 - INFO - epoch:2/50 iteration:1750/1876 batch loss is :6403.9951
2025-01-09 14:10:26 - INFO - epoch:2/50 iteration:1800/1876 batch loss is :7468.8799
2025-01-09 14:10:28 - INFO - epoch:2/50 iteration:1850/1876 batch loss is :6990.1465
2025-01-09 14:10:29 - INFO - Epoch:2/50 Loss is :7212.8467
2025-01-09 14:10:29 - INFO - average reconstruction loss is :7212.8467
2025-01-09 14:10:29 - INFO - average kl divergence is : 0.0000
2025-01-09 14:10:34 - INFO - VAL loss :7346.1304
2025-01-09 14:10:34 - INFO - epoch:3/50 iteration:0/1876 batch loss is :7302.4316
